{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb92cb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a42aa1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages \n",
    "\n",
    "# Manipulation \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import matplotlib as mpl \n",
    "\n",
    "# NLP tasks \n",
    "import string \n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os \n",
    "\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31bffbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#4c72b0', '#dd8452', '#55a868', '#c44e52', '#8172b3', '#937860', '#da8bc3', '#8c8c8c', '#ccb974', '#64b5cd']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAABECAYAAACF4e8fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAACLUlEQVR4nO3ZMWoUcRjG4VmZTTCgkFXSLGiTRtDCaivBzjNYigdI6wG8gF2KVBZ2adJ7gLmHC6LECGoV4e8FNlsI3/7Dy/O0HwsvDMz+YGattTYAAAS703sAAEA1wQMAxBM8AEA8wQMAxBM8AEC8cdvxydPnw/zgcFdbdu7ReNl7Qqkv+/PeE8oc/bjuPaHUr/2HvSeUGmdXvSeUuj9mP7+fw5/eE8rcu5v9bvneFr0nlBp/Xw3TNG2+bfvh/OBwePzipGTUbfBh8bH3hFLvjo96Tyhz8ulb7wmlPh+/6T2h1GLvvPeEUq8evO09odTFbPMfSoKXz772nlDq9O/r3hNKXZ69v/HmkxYAEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEE/wAADxBA8AEG/WWms3HVer1bBcLne5BwDgv6zX62Gapo23rcEDAJDAJy0AIJ7gAQDiCR4AIJ7gAQDiCR4AIN4/T4ww7hBAeXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set styles \n",
    "%matplotlib inline\n",
    "sns.set_style('white')\n",
    "sns.set_palette('deep')\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (16, 10)\n",
    "mpl.rcParams['lines.linewidth'] = 1\n",
    "mpl.rcParams['lines.linestyle'] = '--'\n",
    "mpl.rcParams['font.size'] = 12\n",
    "mpl.rcParams['legend.frameon'] = False \n",
    "\n",
    "background_color = '#f6f5f5'\n",
    "col_blue = '#4c72b0'\n",
    "col_orange = '#dd8452'\n",
    "\n",
    "# Set options \n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Colour palette hex references \n",
    "pal = sns.color_palette('deep')\n",
    "sns.palplot(pal)\n",
    "print(pal.as_hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c82796c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file into pandas using a relative path\n",
    "\n",
    "sms_df = pd.read_csv('C:\\\\Users\\\\sanc\\\\Documents\\\\GitHub\\\\datasets\\\\spam.csv', encoding='latin-1')\n",
    "\n",
    "# drop 3 empty columns\n",
    "sms_df.dropna(axis=1, inplace=True)\n",
    "\n",
    "sms_df.columns = ['label', 'message']\n",
    "sms_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267850ef",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe dataset \n",
    "\n",
    "# describe message dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f4697",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the label to a numeric variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract length from message variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc9f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and calculate average length by spam / not spam\n",
    "\n",
    "# plot as sns.hisplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adee737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08674293",
   "metadata": {},
   "source": [
    "#### Text Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a3893",
   "metadata": {},
   "source": [
    "CLassification algorithms usually need some sort of numerical featlure vector to perform. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In this section we'll convert the raw messages (sequence of characters) into vectors (sequences of numbers).\n",
    "\n",
    "As a first step, let's write a function that will split a message into its individual words and return a list. We'll also remove very common words, ('the', 'a', etc..). To do this we will take advantage of the NLTK library. It's pretty much the standard library in Python for processing text and has a lot of useful features. We'll only use some of the basic ones here.\n",
    "\n",
    "Let's create a function that will process the string in the message column, then we can just use apply() in pandas do process all the text in the DataFrame.\n",
    "\n",
    "First removing punctuation. We can just take advantage of Python's built-in string library to get a quick list of all the possible punctuation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fucntion to process the string in the message column - to be apply() in pandas \n",
    "\n",
    "# first remove punctuation - we can take advantage of Python's built in string library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df11068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    STOPWORDS = stopwords.words('english') + ['u', 'Ã¼', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede48868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c3c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['clean_msg'] = sms.message.apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa4e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = sms[sms.label=='ham'].clean_msg.apply(lambda x: [word.lower() for word in x.split()])\n",
    "ham_words = Counter()\n",
    "\n",
    "for msg in words:\n",
    "    ham_words.update(msg)\n",
    "    \n",
    "print(ham_words.most_common(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
